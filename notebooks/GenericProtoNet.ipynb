{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "from fastprogress import progress_bar\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(sampled_character_folders, labels, texts, nb_samples=None, shuffle=False):\n",
    "    if nb_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, nb_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    texts_labels = [(i, text_vectors[idx]) for i in range(len(sampled_character_folders)) for idx in sampler(list(np.where(np.array(labels) == i)[0]))]\n",
    "    if shuffle:\n",
    "        random.shuffle(texts_labels)\n",
    "    return texts_labels\n",
    "    \n",
    "class TextGenerator(object):\n",
    "    \"\"\"\n",
    "    Data Generator capable of generating batches of text.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, num_classes, num_samples_per_class, num_meta_test_classes, num_meta_test_samples_per_class):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n",
    "            num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "        self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n",
    "        self.num_meta_test_classes = num_meta_test_classes\n",
    "        self.dim_input = 768\n",
    "        self.dim_output = 32\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df['target'].tolist()\n",
    "        #self.nlp = spacy.load('en_trf_bertbaseuncased_lg')\n",
    "        class_list = np.unique(np.array(df['target'].tolist()))\n",
    "        random.seed(1)\n",
    "        random.shuffle(class_list)\n",
    "        num_val = 6\n",
    "        num_train = 8\n",
    "        self.metatrain_character_folders = class_list[: num_train]\n",
    "        self.metaval_character_folders = class_list[num_train:num_train + num_val]\n",
    "        self.metatest_character_folders = class_list[num_train + num_val:]\n",
    "    def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False):\n",
    "        \"\"\"\n",
    "        Samples a batch for training, validation, or testing\n",
    "        Args:\n",
    "            batch_type: meta_train/meta_val/meta_test\n",
    "            shuffle: randomly shuffle classes or not\n",
    "            swap: swap number of classes (N) and number of samples per class (K) or not\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, N, K, 768] and label batch has shape [B, N, K, N] if swap\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"meta_train\":\n",
    "            text_classes = self.metatrain_character_folders\n",
    "            num_classes = self.num_classes\n",
    "            num_samples_per_class = self.num_samples_per_class\n",
    "        elif batch_type == \"meta_val\":\n",
    "            text_classes = self.metaval_character_folders\n",
    "            num_classes = self.num_classes\n",
    "            num_samples_per_class = self.num_samples_per_class\n",
    "        else:\n",
    "            text_classes = self.metatest_character_folders\n",
    "            num_classes = self.num_meta_test_classes\n",
    "            num_samples_per_class = self.num_meta_test_samples_per_class\n",
    "        all_text_batches, all_label_batches = [], []\n",
    "        for i in range(batch_size):\n",
    "            sampled_character_folders = random.sample(list(text_classes), num_classes)\n",
    "            labels_and_texts = get_texts(sampled_character_folders, self.labels, self.texts, nb_samples=num_samples_per_class, shuffle=False)\n",
    "            labels = [li[0] for li in labels_and_texts]\n",
    "            texts_ = [li[1] for li in labels_and_texts]\n",
    "            texts = np.stack(texts_)\n",
    "            labels = np.array(labels)\n",
    "            labels = np.reshape(labels, (num_classes, num_samples_per_class))\n",
    "            labels = np.eye(num_classes)[labels]\n",
    "            texts = np.reshape(texts, (num_classes, num_samples_per_class, -1))\n",
    "            batch = np.concatenate([labels, texts], 2)\n",
    "            if shuffle:\n",
    "                for p in range(num_samples_per_class):\n",
    "                    np.random.shuffle(batch[:, p])\n",
    "            labels = batch[:, :, :num_classes]\n",
    "            texts = batch[:, :, num_classes:]\n",
    "            if swap:\n",
    "                labels = np.swapaxes(labels, 0, 1)\n",
    "                texts = np.swapaxes(texts, 0, 1)\n",
    "            all_text_batches.append(texts)\n",
    "            all_label_batches.append(labels)\n",
    "        all_text_batches = np.stack(all_text_batches)\n",
    "        all_label_batches = np.stack(all_label_batches)\n",
    "        return all_text_batches, all_label_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors = pickle.load(open('../data/mini_newsgroup_vectors.pkl','rb'))\n",
    "mini_df = pickle.load(open('../data/mini_newsgroup_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNetText(torch.nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, proto_dim):\n",
    "        super(ProtoNetText, self).__init__()\n",
    "        self.embed_size = embedding_size\n",
    "        self.proto_dim = proto_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l1 = torch.nn.Linear(self.embed_size, self.hidden_size)\n",
    "        self.rep_block =torch.nn.Sequential(*[torch.nn.BatchNorm1d(hidden_size), torch.nn.Linear(self.hidden_size, self.hidden_size)])\n",
    "        self.final = torch.nn.Linear(self.hidden_size, self.proto_dim)\n",
    "    def forward(self, x):\n",
    "        return self.final(self.rep_block(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries\n",
    "class ProtoLoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes, num_support, num_queries, ndim):\n",
    "        super(ProtoLoss,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_support = num_support\n",
    "        self.num_queries = num_queries\n",
    "        self.ndim = ndim\n",
    "    \n",
    "    def euclidean_distance(self, a, b):\n",
    "        # a.shape = N x D\n",
    "        # b.shape = M x D\n",
    "        N, D = a.shape[0], a.shape[1]\n",
    "        M = b.shape[0]\n",
    "        a = torch.repeat_interleave(a.unsqueeze(1), repeats = M, dim = 1)\n",
    "        b = torch.repeat_interleave(b.unsqueeze(0), repeats = N, dim = 0)\n",
    "        return 1.*torch.sum(torch.pow((a-b), 2),2)\n",
    "        \n",
    "    def forward(self, x, q, labels_onehot):\n",
    "        protox = torch.mean(1.*x.reshape([self.num_classes,self.num_support,self.ndim]),1)\n",
    "        dists = self.euclidean_distance(protox, q)\n",
    "        logpy = torch.log_softmax(-1.*dists,0).transpose(1,0).view(self.num_classes,self.num_queries,self.num_classes)\n",
    "        ce_loss = -1. * torch.mean(torch.mean(logpy * labels_onehot.float(),1))\n",
    "        accuracy = torch.mean((torch.argmax(labels_onehot.float(),-1).float() == torch.argmax(logpy,-1).float()).float())\n",
    "        return ce_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 5\n",
    "k_shot = 5\n",
    "proto_dim = 32\n",
    "n_query = 2\n",
    "n_meta_test_way = 5\n",
    "k_meta_test_shot = 5\n",
    "n_meta_test_query = 2\n",
    "num_epochs = 20\n",
    "num_episodes = 200\n",
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 768\n",
    "model_text = ProtoNetText(embed_size, hidden_dim, proto_dim)\n",
    "optimizer_text = torch.optim.Adam(model_text.parameters(), lr=1e-4)\n",
    "criterion = ProtoLoss(n_way, k_shot, n_query, proto_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator_ = TextGenerator(mini_df, n_way, k_shot+n_query, n_meta_test_way, k_meta_test_shot+n_meta_test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = text_generator_.sample_batch('meta_train', 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 7, 768)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 7, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {i:np.where(y.reshape(-1,n_way)[:,i] == 1.)[0] for i in range(n_way)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 18, 19, 20, 21, 29, 30,  0, 11, 22, 23, 27, 31, 33,  7,  8, 12,\n",
       "       13, 16, 24, 32,  1,  3,  5,  6,  9, 14, 25,  2,  4, 15, 17, 26, 28,\n",
       "       34])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrage_list = []\n",
    "np.ravel([lookup_dict[i] for i in range(n_way)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,n_way)[np.ravel([lookup_dict[i] for i in range(n_way)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lookup_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-01caac568b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrearrage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrearrage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlookup_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lookup_list' is not defined"
     ]
    }
   ],
   "source": [
    "map(rearrage_list.append(lookup_list), [lookup_dict[i] for i in range(n_way)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([10, 18, 19, 20, 21, 29, 30])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 18, 19, 20, 21])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_dict[0][:n_way]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_latents(x,y, embed_size, n_way, n_query, k_shot):\n",
    "    lookup_dict = {i:np.where(y.reshape(-1,n_way)[:,i] == 1.)[0] for i in range(n_way)}\n",
    "    lookup_list = np.ravel([lookup_dict[i] for i in range(n_way)])\n",
    "    ### \n",
    "    x_shuffle = x.reshape(-1, embed_size)[lookup_list].reshape(1, n_way, n_query, embed_size)\n",
    "    y_shuffle = y.reshape(-1, n_way)[lookup_list].reshape(1, n_way, n_query, n_way)\n",
    "    ###\n",
    "    x_support, x_query = x_shuffle[:,:,:k_shot,:], x_shuffle[:,:,k_shot:,:]\n",
    "    y_support, y_query = y_shuffle[:,:,:k_shot,:], y_shuffle[:,:,k_shot:,:]\n",
    "    labels_onehot = y_query.reshape(n_way, n_query, n_way)\n",
    "    support_input_t = torch.Tensor(x_support).view(-1, embed_size)\n",
    "    query_input_t = torch.Tensor(x_query).view(-1, embed_size)\n",
    "    return support_input_t, query_input_t, labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5, 768)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:,:k_shot,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 7, 768)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs330hw2",
   "language": "python",
   "name": "cs330hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
